{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca09761db8545719",
   "metadata": {},
   "source": [
    "# Optimizing Access Patterns\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this page we will be showing how we can take an existing MDIO and add\n",
    "fast access, lossy, versions of the data in X/Y/Z cross-sections (slices).\n",
    "\n",
    "We can re-use the MDIO dataset we created in the [Quickstart](#quickstart) notebook.\n",
    "Please run it first.\n",
    "\n",
    "We will define our compression levels first. We will use this to adjust the quality\n",
    "of the lossy compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T02:40:52.720542Z",
     "start_time": "2024-03-12T02:40:52.716236Z"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class MdioZfpQuality(float, Enum):\n",
    "    \"\"\"Config options for ZFP compression.\"\"\"\n",
    "\n",
    "    VERY_LOW = 6\n",
    "    LOW = 3\n",
    "    MEDIUM = 1\n",
    "    HIGH = 0.1\n",
    "    VERY_HIGH = 0.01\n",
    "    ULTRA = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a09a89-b453-4c3e-b879-14caaedd29de",
   "metadata": {},
   "source": [
    "We will use the lower level `MDIOAccessor` to open the existing file in write mode that\n",
    "allows us to modify its raw metadata. This can be dangerous, we recommend using only provided\n",
    "tools to avoid data corruption.\n",
    "\n",
    "We specify the original access pattern of the source data `\"012\"` with some parameters like\n",
    "caching. For the rechunking, we recommend using the single threaded `\"zarr\"` backend to avoid\n",
    "race conditions.\n",
    "\n",
    "We also define a `dict` for common arguments in rechunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45558306-ab9c-46aa-a299-8758a911b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdio.api.accessor import MDIOAccessor\n",
    "\n",
    "mdio_path = \"filt_mig.mdio\"\n",
    "\n",
    "orig_mdio_cached = MDIOAccessor(\n",
    "    mdio_path_or_buffer=mdio_path,\n",
    "    mode=\"w\",\n",
    "    access_pattern=\"012\",\n",
    "    storage_options=None,\n",
    "    return_metadata=False,\n",
    "    new_chunks=None,\n",
    "    backend=\"zarr\",\n",
    "    memory_cache_size=2**28,\n",
    "    disk_cache=False,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Compression\n",
    "\n",
    "Now, let's define our compression level. The compression ratios vary a lot\n",
    "on the data characteristics. However, the compression levels here are good\n",
    "guidelines that are based on standard deviation of the original data.\n",
    "\n",
    "We use ZFP's fixed accuracy mode with a tolerance based on data standard\n",
    "deviation, as mentioned above. For more ZFP options you can see its documentation.\n",
    "\n",
    "Empirically, for this dataset, we see the following size reductions (per copy):\n",
    "\n",
    "* `10  : 1` on `VERY_LOW`\n",
    "* `7.5 : 1` on `LOW`\n",
    "* `4.5 : 1` on `MEDIUM`\n",
    "* `3   : 1` on `HIGH`\n",
    "* `2   : 1` on `VERY_HIGH`\n",
    "* `1.5 : 1` on `ULTRA`"
   ],
   "id": "8b06cb28e6792bea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from numcodecs import ZFPY\n",
    "from zfpy import mode_fixed_accuracy\n",
    "\n",
    "std = orig_mdio_cached.stats[\"std\"]  # standard deviation of original data\n",
    "\n",
    "quality = MdioZfpQuality.LOW\n",
    "tolerance = quality * std\n",
    "sample_compressor = ZFPY(mode_fixed_accuracy, tolerance=tolerance)\n",
    "\n",
    "common_kwargs = {\"overwrite\": True, \"compressor\": sample_compressor}"
   ],
   "id": "b964ef9c823772f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Optimizing IL/XL/Z Independently\n",
    "\n",
    "In this cell, we will demonstrate how to create IL/XL and Z (two-way-time) optimized\n",
    "versions **independently**. In the next section we will do the same with the batch\n",
    "mode where the data only needs to be read into memory once.\n",
    "\n",
    "In the example below, each rechunking operation will read the data from the original\n",
    "MDIO dataset and discard it. We did enable 256 MB (2^28 bytes) memory cache above,\n",
    "it will help some, but still not ideal."
   ],
   "id": "745a0ca6ef69a34a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from mdio.api.convenience import rechunk\n",
    "\n",
    "rechunk(orig_mdio_cached, (4, 512, 512), suffix=\"fast_il\", **common_kwargs)\n",
    "rechunk(orig_mdio_cached, (512, 4, 512), suffix=\"fast_xl\", **common_kwargs)\n",
    "rechunk(orig_mdio_cached, (512, 512, 4), suffix=\"fast_z\", **common_kwargs)"
   ],
   "id": "935791a6cdb92b45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can now open the original MDIO dataset and the fast access patterns.\n",
    "When printing the `chunks` attribute, we see the original one first, and\n",
    "the subsequent ones show data is rechunked with ZFP compression."
   ],
   "id": "e1c0b356e2bc4dd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from mdio import MDIOReader\n",
    "\n",
    "orig_mdio = MDIOReader(mdio_path)\n",
    "il_mdio = MDIOReader(mdio_path, access_pattern=\"fast_il\")\n",
    "xl_mdio = MDIOReader(mdio_path, access_pattern=\"fast_xl\")\n",
    "z_mdio = MDIOReader(mdio_path, access_pattern=\"fast_z\")\n",
    "\n",
    "print(orig_mdio.chunks, orig_mdio._traces.compressor)\n",
    "print(il_mdio.chunks, il_mdio._traces.compressor)\n",
    "print(xl_mdio.chunks, xl_mdio._traces.compressor)\n",
    "print(z_mdio.chunks, z_mdio._traces.compressor)"
   ],
   "id": "40d50ed493f7ce9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can now compare the sizes of the compressed representations to original.\n",
    "\n",
    "Below commands are for UNIX based operating systems and won't work on Windows."
   ],
   "id": "e9e915119bce64ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!du -hs {mdio_path}/data/chunked_012\n",
    "!du -hs {mdio_path}/data/chunked_fast_il\n",
    "!du -hs {mdio_path}/data/chunked_fast_xl\n",
    "!du -hs {mdio_path}/data/chunked_fast_z"
   ],
   "id": "bf0fc40df9f96717"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Comparing local disk read speeds for inlines:",
   "id": "26aec88175da201"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%timeit orig_mdio[175]  # 3d chunked\n",
    "%timeit il_mdio[175]  # inline optimized"
   ],
   "id": "1134b6305be6a85a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For crosslines:",
   "id": "6f670e07addcc627"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%timeit orig_mdio[:, 90]  # 3d chunked\n",
    "%timeit xl_mdio[:, 90]  # xline optimized"
   ],
   "id": "82ebd608f6707735"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, for Z (time-slices):",
   "id": "5b7fadd3f50d7019"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%timeit orig_mdio[..., 751]  # 3d chunked\n",
    "%timeit z_mdio[..., 751]  # time-slice optimized"
   ],
   "id": "886e5b13b21b0b74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can check the subjective quality of the compression by visually comparing\n",
    "two inlines. Similar to the example we had in the [Compression](#compression) page."
   ],
   "id": "9b50c4a230631f6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "vmin = -3 * std\n",
    "vmax = 3 * std\n",
    "\n",
    "imshow_kw = dict(vmin=vmin, vmax=vmax, cmap=\"gray_r\", interpolation=\"bilinear\", aspect=\"auto\")\n",
    "\n",
    "\n",
    "def attach_colorbar(image, axis):\n",
    "    divider = make_axes_locatable(axis)\n",
    "    cax = divider.append_axes(\"top\", size=\"2%\", pad=0.05)\n",
    "    plt.colorbar(image, cax=cax, orientation=\"horizontal\")\n",
    "    cax.xaxis.set_ticks_position(\"top\")\n",
    "    cax.tick_params(labelsize=8)\n",
    "\n",
    "\n",
    "def plot_image_and_cbar(data, axis, title):\n",
    "    image = axis.imshow(data.T, **imshow_kw)\n",
    "    attach_colorbar(image, axis)\n",
    "    axis.set_title(title, y=-0.15)\n",
    "\n",
    "\n",
    "def plot_inlines_with_diff(orig, compressed, title):\n",
    "    fig, ax = plt.subplots(1, 4, sharey=\"all\", sharex=\"all\", figsize=(8, 5))\n",
    "\n",
    "    diff = orig[200] - compressed[200]\n",
    "\n",
    "    plot_image_and_cbar(orig[200], ax[0], \"original\")\n",
    "    plot_image_and_cbar(compressed[200], ax[1], \"lossy\")\n",
    "    plot_image_and_cbar(diff, ax[2], \"difference\")\n",
    "    plot_image_and_cbar(diff * 1_000, ax[3], \"1,000x difference\")\n",
    "\n",
    "    plt.suptitle(f\"{title} ({std=})\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_inlines_with_diff(orig_mdio, il_mdio, \"\")"
   ],
   "id": "fbaeb4daa79fd21a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In conclusion, we show that by generating optimized, lossy compressed copies of the data\n",
    "for certain access patterns yield big performance benefits when reading the data.\n",
    "\n",
    "The differences are orders of magnitude larger on big datasets and remote stores, given available\n",
    "network bandwidth."
   ],
   "id": "11777b49a6bb44e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Optimizing in Batch\n",
    "\n",
    "Now that we understand how rechunking and lossy compression works, we will demonstrate how\n",
    "to do this in batches. \n",
    "\n",
    "The benefit of doing the batched processing is that the dataset gets read once. This is\n",
    "especially important if the original MDIO resides in a remote store like AWS S3, or Google\n",
    "Cloud's GCS.\n",
    "\n",
    "Note that we not are overwriting the old optimized chunks, just creating new ones with the\n",
    "suffix 2 to demonstrate we can create as many version of the original data as we want."
   ],
   "id": "18a50fd9862b9d95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from mdio.api.convenience import rechunk_batch\n",
    "\n",
    "rechunk_batch(\n",
    "    orig_mdio_cached,\n",
    "    chunks_list=[(4, 512, 512), (512, 4, 512), (512, 512, 4)],\n",
    "    suffix_list=[\"fast_il2\", \"fast_xl2\", \"fast_z2\"],\n",
    "    **common_kwargs,\n",
    ")"
   ],
   "id": "37b46ff0c5d64e86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from mdio import MDIOReader\n",
    "\n",
    "orig_mdio = MDIOReader(mdio_path)\n",
    "il2_mdio = MDIOReader(mdio_path, access_pattern=\"fast_il2\")\n",
    "xl2_mdio = MDIOReader(mdio_path, access_pattern=\"fast_xl2\")\n",
    "z2_mdio = MDIOReader(mdio_path, access_pattern=\"fast_z2\")\n",
    "\n",
    "print(orig_mdio.chunks, orig_mdio._traces.compressor)\n",
    "print(il_mdio.chunks, il2_mdio._traces.compressor)\n",
    "print(xl_mdio.chunks, xl2_mdio._traces.compressor)\n",
    "print(z_mdio.chunks, z2_mdio._traces.compressor)"
   ],
   "id": "37ce790e38e754db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "baeafdda5539a9e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
